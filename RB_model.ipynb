{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efafb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "import string\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5080178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment1_Notes</th>\n",
       "      <th>Segment2_Notes</th>\n",
       "      <th>Segment3_Notes</th>\n",
       "      <th>Segment4_Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>6266293</td>\n",
       "      <td>laser invent earli th centuri follow einstein ...</td>\n",
       "      <td>make laser involv two main part load atom elec...</td>\n",
       "      <td>differ type lightenergi exist quanta repres sm...</td>\n",
       "      <td>the film goldfing one first exposur gener popu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>6416079</td>\n",
       "      <td>laser invent earli th centuri build einstein s...</td>\n",
       "      <td>to make laser need two basic part load atom kn...</td>\n",
       "      <td>laser light come variou type includ solidst ga...</td>\n",
       "      <td>laser use divers widespread carbon dioxid lase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>6265686</td>\n",
       "      <td>the maser invent charl town arthur schawlow in...</td>\n",
       "      <td>to make laser load atom electron someth stimul...</td>\n",
       "      <td>there differ type laser light form electromagn...</td>\n",
       "      <td>laser use divers widespread instanc carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>6260581</td>\n",
       "      <td>the histori laser begin earli nt einstein s in...</td>\n",
       "      <td>to make laser beam load atom electron stimul r...</td>\n",
       "      <td>laser categor sever type base medium use solid...</td>\n",
       "      <td>jame bond famous featur laser one adventur gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>6269286</td>\n",
       "      <td>laser develop maser like laser invis invent to...</td>\n",
       "      <td>red laser make rubi crystal flash tube wrap ar...</td>\n",
       "      <td>energi exist quantum laser light monochromat c...</td>\n",
       "      <td>laser precis easi use cut util industri cut we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment    Topic       ID  \\\n",
       "0           1  Physics  6266293   \n",
       "1           1  Physics  6416079   \n",
       "2           1  Physics  6265686   \n",
       "3           1  Physics  6260581   \n",
       "4           1  Physics  6269286   \n",
       "\n",
       "                                      Segment1_Notes  \\\n",
       "0  laser invent earli th centuri follow einstein ...   \n",
       "1  laser invent earli th centuri build einstein s...   \n",
       "2  the maser invent charl town arthur schawlow in...   \n",
       "3  the histori laser begin earli nt einstein s in...   \n",
       "4  laser develop maser like laser invis invent to...   \n",
       "\n",
       "                                      Segment2_Notes  \\\n",
       "0  make laser involv two main part load atom elec...   \n",
       "1  to make laser need two basic part load atom kn...   \n",
       "2  to make laser load atom electron someth stimul...   \n",
       "3  to make laser beam load atom electron stimul r...   \n",
       "4  red laser make rubi crystal flash tube wrap ar...   \n",
       "\n",
       "                                      Segment3_Notes  \\\n",
       "0  differ type lightenergi exist quanta repres sm...   \n",
       "1  laser light come variou type includ solidst ga...   \n",
       "2  there differ type laser light form electromagn...   \n",
       "3  laser categor sever type base medium use solid...   \n",
       "4  energi exist quantum laser light monochromat c...   \n",
       "\n",
       "                                      Segment4_Notes  \n",
       "0  the film goldfing one first exposur gener popu...  \n",
       "1  laser use divers widespread carbon dioxid lase...  \n",
       "2  laser use divers widespread instanc carbon dio...  \n",
       "3  jame bond famous featur laser one adventur gol...  \n",
       "4  laser precis easi use cut util industri cut we...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df = pd.read_csv('note classification\\\\Cleaned_Notes.csv')\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text\n",
    "def remove_numbers(text): \n",
    "    result = re.sub(r'\\d+', '', text) \n",
    "    return result\n",
    "def remove_slash_with_space(text): \n",
    "    return text.replace('\\\\', \" \")\n",
    "def remove_punctuation(text): \n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator) \n",
    "def text_lowercase(text): \n",
    "    return text.lower()     \n",
    "def remove_whitespace(text): \n",
    "    return  \" \".join(text.split()) \n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return ' '.join(filtered_text)\n",
    "def stem_words(text): \n",
    "    stemmer = PorterStemmer() \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    return ' '.join(stems)\n",
    "def lemmatize_words(text): \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    word_tokens = word_tokenize(text) \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return ' '.join(lemmas) \n",
    "\n",
    "\n",
    "def perform_preprocessing(text):\n",
    "    text = remove_accented_chars(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = text_lowercase(text)\n",
    "    text = remove_slash_with_space(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = stem_words(text)\n",
    "    text = lemmatize_words(text)\n",
    "    text = remove_whitespace(text)\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to each segment\n",
    "notes_df['Segment1_Notes'] = notes_df['Segment1_Notes'].apply(perform_preprocessing)\n",
    "notes_df['Segment2_Notes'] = notes_df['Segment2_Notes'].apply(perform_preprocessing)\n",
    "notes_df['Segment3_Notes'] = notes_df['Segment3_Notes'].apply(perform_preprocessing)\n",
    "notes_df['Segment4_Notes'] = notes_df['Segment4_Notes'].apply(perform_preprocessing)\n",
    "\n",
    "notes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8aa6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment</th>\n",
       "      <th>IdeaUnit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260226</td>\n",
       "      <td>1</td>\n",
       "      <td>declar knowledg factual statement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260226</td>\n",
       "      <td>1</td>\n",
       "      <td>imper knowledg solv problem accomplish task</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260226</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm instruct step complet specif order</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260226</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm outlin begin middl end</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260226</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm contain loop instruct tell program r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Topic       ID  Segment  \\\n",
       "0  ComputerScience  6260226        1   \n",
       "1  ComputerScience  6260226        1   \n",
       "2  ComputerScience  6260226        1   \n",
       "3  ComputerScience  6260226        1   \n",
       "4  ComputerScience  6260226        1   \n",
       "\n",
       "                                            IdeaUnit  label  \n",
       "0                  declar knowledg factual statement      1  \n",
       "1        imper knowledg solv problem accomplish task      1  \n",
       "2       algorithm instruct step complet specif order      1  \n",
       "3                   algorithm outlin begin middl end      0  \n",
       "4  algorithm contain loop instruct tell program r...      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('note classification\\\\train.csv')\n",
    "\n",
    "train_df['IdeaUnit'] = train_df['IdeaUnit'].apply(perform_preprocessing)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca5adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComputerScience 6260226 declar knowledg factual statement\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: declar knowledg factual statement\n",
      "Similarity: 5.0230601312971554e-160\n",
      "ComputerScience 6260226 imper knowledg solv problem accomplish task\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: imper knowledg solv problem accomplish task\n",
      "Similarity: 2.5426907651115945e-158\n",
      "ComputerScience 6260226 algorithm instruct step complet specif order\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: algorithm instruct step complet specif order\n",
      "Similarity: 5.139193493429783e-235\n",
      "ComputerScience 6260226 algorithm outlin begin middl end\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: algorithm outlin begin middl end\n",
      "Similarity: 6.755848466934435e-236\n",
      "ComputerScience 6260226 algorithm contain loop instruct tell program repeat\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: algorithm contain loop instruct tell program repeat\n",
      "Similarity: 8.019036214974401e-81\n",
      "ComputerScience 6260226 proper termin instruct crucial algorithm prevent infinit loop\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: proper termin instruct crucial algorithm prevent infinit loop\n",
      "Similarity: 2.4544090060409583e-157\n",
      "ComputerScience 6260226 one first comput design iowa state univers atanasoff berri\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: one first comput design iowa state univers atanasoff berri\n",
      "Similarity: 7.087209758789978e-234\n",
      "ComputerScience 6260226 earli comput call fix program comput design specif problem\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: earli comput call fix program comput design specif problem\n",
      "Similarity: 5.8028210637173526e-157\n",
      "ComputerScience 6260226 the atanasoff berri comput abc make help drop bomb world war ii\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: the atanasoff berri comput abc make help drop bomb world war ii\n",
      "Similarity: 2.9558495519468576e-233\n",
      "ComputerScience 6260226 alan ture s machin build alli decod german militari messag world war ii\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: alan ture s machin build alli decod german militari messag world war ii\n",
      "Similarity: 4.095665728700435e-233\n",
      "ComputerScience 6260226 earli comput oper execut set algorithm separ receiv oper input\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: earli comput oper execut set algorithm separ receiv oper input\n",
      "Similarity: 1.6553617538550678e-233\n",
      "ComputerScience 6260226 fix program comput limit function capabl perform predefin task\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: fix program comput limit function capabl perform predefin task\n",
      "Similarity: 5.8028210637173526e-157\n",
      "ComputerScience 6260226 the invent store program comput mark signific technolog breakthrough\n",
      "Segment Idea: declar knowledg consist factual statement wherea imper knowledg compris howto statement express algorithm step exact order perform comput an algorithm contain loop tell program start repeat process must includ termin code if termin code miss infinit loop occur caus program run forev a fix program machin execut algorithm wherea store program comput advanc concept\n",
      "Student Note: the invent store program comput mark signific technolog breakthrough\n",
      "Similarity: 2.718278041206819e-80\n",
      "ComputerScience 6260226 in store program comput algorithm data applic program\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: in store program comput algorithm data applic program\n",
      "Similarity: 2.7946566639405936e-159\n",
      "ComputerScience 6260226 program produc program\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: program produc program\n",
      "Similarity: 2.379242416657224e-244\n",
      "ComputerScience 6260226 store program comput consist three main part control unit memori arithmet logic unit alu\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: store program comput consist three main part control unit memori arithmet logic unit alu\n",
      "Similarity: 0.0010359563769756172\n",
      "ComputerScience 6260226 store program comput also input output devic part regularli interact\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: store program comput also input output devic part regularli interact\n",
      "Similarity: 1.4333130088175393e-81\n",
      "ComputerScience 6260226 keyboard mice screen exampl input output devic\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: keyboard mice screen exampl input output devic\n",
      "Similarity: 4.674685943331244e-83\n",
      "ComputerScience 6260226 a comput memori store inform receiv\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: a comput memori store inform receiv\n",
      "Similarity: 3.697649305188171e-84\n",
      "ComputerScience 6260226 comput one kind memori separ system\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: comput one kind memori separ system\n",
      "Similarity: 9.12773978589568e-238\n",
      "ComputerScience 6260226 the control unit tell comput\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: the control unit tell comput\n",
      "Similarity: 2.768252682985807e-162\n",
      "ComputerScience 6260226 the arithmet logic unit alu fundament part modern comput act comput brain\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: the arithmet logic unit alu fundament part modern comput act comput brain\n",
      "Similarity: 0.0003304439339166433\n",
      "ComputerScience 6260226 modern alu billion transistor\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: modern alu billion transistor\n",
      "Similarity: 4.273386982817057e-241\n",
      "ComputerScience 6260226 transistor alu see equival light bulb\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: transistor alu see equival light bulb\n",
      "Similarity: 8.247843958964405e-238\n",
      "ComputerScience 6260226 comput use binari system interpret\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: comput use binari system interpret\n",
      "Similarity: 2.768252682985807e-162\n",
      "ComputerScience 6260226 modern comput turn lightbulb billion time everi second\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: modern comput turn lightbulb billion time everi second\n",
      "Similarity: 3.9257630270767706e-236\n",
      "ComputerScience 6260226 complex oper possibl due larg number quick switch transistor make\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: complex oper possibl due larg number quick switch transistor make\n",
      "Similarity: 3.7031720134913914e-235\n",
      "ComputerScience 6260226 the binari system allow comput process larg amount data execut algorithm effici\n",
      "Segment Idea: the store program concept treat instruct like data allow program chang time produc data even produc anoth program comput program the comput s main compon includ memori store inform control unit cu direct comput s action instruct alu input output devic arithmet logic unit alu perform comput logic oper effect act brain comput input output devic compris element keyboard mice screen the alu contain transistor execut numer oper these transistor oper conjunct binari system util repres state respect elimin need anyth express use in binari system number correspond sequenc lightbulb exampl includ\n",
      "Student Note: the binari system allow comput process larg amount data execut algorithm effici\n",
      "Similarity: 9.10975499536437e-158\n",
      "ComputerScience 6260226 command builtin instruct comput program\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: command builtin instruct comput program\n",
      "Similarity: 2.6779769537298573e-236\n",
      "ComputerScience 6260226 builtin instruct type data differ among program languag\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: builtin instruct type data differ among program languag\n",
      "Similarity: 1.0789253326980627e-157\n",
      "ComputerScience 6260226 in python command str mean string repres charact letter\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: in python command str mean string repres charact letter\n",
      "Similarity: 2.9792676727954034e-157\n",
      "ComputerScience 6260226 syntax static semant semant defin program languag\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: syntax static semant semant defin program languag\n",
      "Similarity: 5.836631213121192e-158\n",
      "ComputerScience 6260226 syntax tell us sequenc charact symbol allow program languag rule\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: syntax tell us sequenc charact symbol allow program languag rule\n",
      "Similarity: 5.8028210637173526e-157\n",
      "ComputerScience 6260226 syntax comput program like syntax human languag\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: syntax comput program like syntax human languag\n",
      "Similarity: 8.624752991311602e-235\n",
      "ComputerScience 6260226 syntax care someth mean fit program languag rule\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: syntax care someth mean fit program languag rule\n",
      "Similarity: 1.225895857983961e-157\n",
      "ComputerScience 6260226 static semant refer mean wellform code\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: static semant refer mean wellform code\n",
      "Similarity: 8.475898956436196e-82\n",
      "ComputerScience 6260226 program languag unlik human languag one mean\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: program languag unlik human languag one mean\n",
      "Similarity: 4.512037967920304e-158\n",
      "ComputerScience 6260226 a bug error code goe intent coder\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: a bug error code goe intent coder\n",
      "Similarity: 5.767719945755799e-235\n",
      "ComputerScience 6260226 error caus program quit result crash\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: error caus program quit result crash\n",
      "Similarity: 1.890603630434861e-235\n",
      "ComputerScience 6260226 error also caus program becom unrespons result freez\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: error also caus program becom unrespons result freez\n",
      "Similarity: 2.1433939874690802e-234\n",
      "ComputerScience 6260226 crash freez differ underli caus\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: crash freez differ underli caus\n",
      "Similarity: 2.8776735125945543e-236\n",
      "ComputerScience 6260226 incompat program expect one input get anoth caus crash\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: incompat program expect one input get anoth caus crash\n",
      "Similarity: 0.0011875852960045047\n",
      "ComputerScience 6260226 when program get stick infinit loop complet job caus freez\n",
      "Segment Idea: program involv syntax semant command program languag provid primit command defin command legal combin in java charact letter repres char python repres str the syntax program languag determin sequenc charact legal static semant oper mean command semant refer mean command crash caus incompat program expect one output get someth differ a freez hand occur infinit loop caus comput unsur stop\n",
      "Student Note: when program get stick infinit loop complet job caus freez\n",
      "Similarity: 5.107130924689723e-157\n",
      "ComputerScience 6260226 if program crash freez know someth go wrong immedi\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: if program crash freez know someth go wrong immedi\n",
      "Similarity: 4.285199083213895e-234\n",
      "ComputerScience 6260226 the challeng type error program run complet produc wrong output\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: the challeng type error program run complet produc wrong output\n",
      "Similarity: 0.0036507682058442856\n",
      "ComputerScience 6260226 python interpret languag make debug easi\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: python interpret languag make debug easi\n",
      "Similarity: 6.033174102415413e-82\n",
      "ComputerScience 6260226 interpret languag describ go wrong use languag sourc code\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: interpret languag describ go wrong use languag sourc code\n",
      "Similarity: 0.0011419433334582134\n",
      "ComputerScience 6260226 compil languag program give unintellig error messag machin code\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: compil languag program give unintellig error messag machin code\n",
      "Similarity: 2.950376203550955e-157\n",
      "ComputerScience 6260226 in almost program languag first see integr develop environ ide python call idl\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: in almost program languag first see integr develop environ ide python call idl\n",
      "Similarity: 0.005729703282006605\n",
      "ComputerScience 6260226 idl name eric idl monti python also inspir name python\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: idl name eric idl monti python also inspir name python\n",
      "Similarity: 7.427864364544552e-234\n",
      "ComputerScience 6260226 the idl highlight autocomplet smart indent help see write code\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: the idl highlight autocomplet smart indent help see write code\n",
      "Similarity: 7.427864364544552e-234\n",
      "ComputerScience 6260226 the shell idl python run code\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: the shell idl python run code\n",
      "Similarity: 1.7197002643195993e-235\n",
      "ComputerScience 6260226 you write run code text editor mani line code execut togeth\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: you write run code text editor mani line code execut togeth\n",
      "Similarity: 1.262850162188788e-233\n",
      "ComputerScience 6260226 everyth object python mani categori tell kind object\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: everyth object python mani categori tell kind object\n",
      "Similarity: 1.437258494844447e-234\n",
      "ComputerScience 6260226 there two type number program integ float point\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: there two type number program integ float point\n",
      "Similarity: 1.8915385549599083e-234\n",
      "ComputerScience 6260226 integ deal whole number notat int python\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: integ deal whole number notat int python\n",
      "Similarity: 6.580250240072275e-235\n",
      "ComputerScience 6260226 float point deal decim notat float python\n",
      "Segment Idea: the worst type error occur program run complet produc wrong output python interpret languag someth goe wrong interpret display error messag use languag sourc code wherea compil languag error messag typic anoth languag an integr develop environ ide tool use program in python integ repres int string repres str latter typic enclos quotat mark a simpl program creat use print function\n",
      "Student Note: float point deal decim notat float python\n",
      "Similarity: 4.999908952924021e-235\n",
      "Ecology 6260215 the word toucan come tupi nativ brazil\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: the word toucan come tupi nativ brazil\n",
      "Similarity: 2.6542869839879695e-238\n",
      "Ecology 6260215 the toucan member ramphastida bird famili\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: the toucan member ramphastida bird famili\n",
      "Similarity: 1.162047316059481e-162\n",
      "Ecology 6260215 toucan mostli find south america\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: toucan mostli find south america\n",
      "Similarity: 2.0586958551148715e-87\n",
      "Ecology 6260215 the largest toucan speci toco toucan\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: the largest toucan speci toco toucan\n",
      "Similarity: 1.2860167545193482e-162\n",
      "Ecology 6260215 the averag lifespan toucan captiv year\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: the averag lifespan toucan captiv year\n",
      "Similarity: 2.1222787270749245e-239\n",
      "Ecology 6260215 toucan migrat beak size\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: toucan migrat beak size\n",
      "Similarity: 1.3601254024964516e-243\n",
      "Ecology 6260215 the anatomi toucan help stand tree long period time\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: the anatomi toucan help stand tree long period time\n",
      "Similarity: 1.2068861385333734e-236\n",
      "Ecology 6260215 toucan reli natur tree hollow woodpeck make tree hole babi\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: toucan reli natur tree hollow woodpeck make tree hole babi\n",
      "Similarity: 2.087167679551854e-159\n",
      "Ecology 6260215 due uniqu anatomi toucan fit insid one tree hole\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: due uniqu anatomi toucan fit insid one tree hole\n",
      "Similarity: 5.875674039001245e-160\n",
      "Ecology 6260215 both toucan parent take care babi\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: both toucan parent take care babi\n",
      "Similarity: 1.162047316059481e-162\n",
      "Ecology 6260215 babi toucan toucanet hatch blind nake\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: babi toucan toucanet hatch blind nake\n",
      "Similarity: 1.975002895784912e-239\n",
      "Ecology 6260215 unlik mother bird toucan leav nest togeth toucanet fli\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: unlik mother bird toucan leav nest togeth toucanet fli\n",
      "Similarity: 1.3127992146241589e-236\n",
      "Ecology 6260215 femal toucan lay egg\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: femal toucan lay egg\n",
      "Similarity: 1.3601254024964516e-243\n",
      "Ecology 6260215 mother father toucan take turn sit egg hatch\n",
      "Segment Idea: the toucan find south america compris speci ring largest toco toucan measur inch smallest aracari toucanet measur inch weigh ounc these bird short bodi round tail live year captiv they migrat adept fli instead hop tree branch notabl larger toucan bigger bill four toe first fourth turn backward help grasp branch stand they rais children tree hole often natur hole creat woodpeck interestingli fit small hole sleep head turn backward tail pull upward mani five six bird fit one hole both parent take turn sit egg although impati sometim leav egg uncov the egg hatch two week young bird develop feather four week learn fli seven week mother leav famili remain togeth bird know play\n",
      "Student Note: mother father toucan take turn sit egg hatch\n",
      "Similarity: 6.637904362011263e-07\n",
      "Ecology 6260215 the color toucan come skin feather\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: the color toucan come skin feather\n",
      "Similarity: 2.3141084876796148e-238\n",
      "Ecology 6260215 toucan cover feather except around feet bill eye\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan cover feather except around feet bill eye\n",
      "Similarity: 1.5752046482611058e-236\n",
      "Ecology 6260215 toucan use color feather mimic fruit avoid predat\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan use color feather mimic fruit avoid predat\n",
      "Similarity: 1.4481214142742536e-236\n",
      "Ecology 6260215 the gender toucan hard determin look\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: the gender toucan hard determin look\n",
      "Similarity: 2.036674040220101e-238\n",
      "Ecology 6260215 the structur toucan bill look like honeycomb\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: the structur toucan bill look like honeycomb\n",
      "Similarity: 2.3323533162440236e-237\n",
      "Ecology 6260215 a toucan bill compos protein keratin\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: a toucan bill compos protein keratin\n",
      "Similarity: 2.1885486845461263e-238\n",
      "Ecology 6260215 a toucan bill consist hard spong\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: a toucan bill consist hard spong\n",
      "Similarity: 2.036674040220101e-238\n",
      "Ecology 6260215 a toucan bill offer two main advantag forag commun\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: a toucan bill offer two main advantag forag commun\n",
      "Similarity: 5.717886013085243e-236\n",
      "Ecology 6260215 toucan take advantag larg bill intimid smaller bird\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan take advantag larg bill intimid smaller bird\n",
      "Similarity: 1.3695486763677508e-236\n",
      "Ecology 6260215 toucan reach deeper place get food bill\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan reach deeper place get food bill\n",
      "Similarity: 2.3323533162440236e-237\n",
      "Ecology 6260215 toucan eat digest period\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan eat digest period\n",
      "Similarity: 4.9846245630523526e-242\n",
      "Ecology 6260215 to tri find mate toucan use bill toss berri one anoth\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: to tri find mate toucan use bill toss berri one anoth\n",
      "Similarity: 3.6823238230933974e-235\n",
      "Ecology 6260215 toucan manag bodi temperatur bill\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan manag bodi temperatur bill\n",
      "Similarity: 7.355159306450285e-240\n",
      "Ecology 6260215 toucan mostli eat fruit occasion eat lizard insect\n",
      "Segment Idea: the toco toucan conspicu bird black feather color keelbil beak except bill feet area around eye the area around eye color skin the toucan s color appear help surviv blend fruit the bill half length bodi yet quit light hollow honeycomb keratin provid balanc strength ratio hard spongelik edg enabl eat meat the long gray narrow tongu use forag intimid small bird well commun the long bill provid reach allow toucan throw food back throat sawlik edg tear fruit the toucan long digest time around minut eat insect offer sourc protein fruit often use gift when s hot heat send bill\n",
      "Student Note: toucan mostli eat fruit occasion eat lizard insect\n",
      "Similarity: 1.4481214142742536e-236\n",
      "Ecology 6260215 deforest export toucan caus popul decreas\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: deforest export toucan caus popul decreas\n",
      "Similarity: 5.111778155289068e-159\n",
      "Ecology 6260215 toco redbil swainson keelbil toucan commonli export us\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: toco redbil swainson keelbil toucan commonli export us\n",
      "Similarity: 1.1472761276117146e-234\n",
      "Ecology 6260215 in exot anim common pet us\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: in exot anim common pet us\n",
      "Similarity: 7.424472526003145e-236\n",
      "Ecology 6260215 a toucan diet fresh fruit make own one expens\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: a toucan diet fresh fruit make own one expens\n",
      "Similarity: 1.3376504161316172e-157\n",
      "Ecology 6260215 to keep toucan entertain need toy\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: to keep toucan entertain need toy\n",
      "Similarity: 8.216529507839683e-236\n",
      "Ecology 6260215 toucan need larg space thrive unlik parrot\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: toucan need larg space thrive unlik parrot\n",
      "Similarity: 3.7159865579147166e-235\n",
      "Ecology 6260215 own toucan demand time space money\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: own toucan demand time space money\n",
      "Similarity: 8.216529507839683e-236\n",
      "Ecology 6260215 avicultur breed rear bird\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: avicultur breed rear bird\n",
      "Similarity: 3.0690394905109463e-238\n",
      "Ecology 6260215 toucan cost due suppli demand\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: toucan cost due suppli demand\n",
      "Similarity: 6.129089056875124e-160\n",
      "Ecology 6260215 due declin toucan popul defend wildlif becam dedic help toucan\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: due declin toucan popul defend wildlif becam dedic help toucan\n",
      "Similarity: 2.959609679061537e-157\n",
      "Ecology 6260215 more million exot bird export us\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: more million exot bird export us\n",
      "Similarity: 8.829235553065548e-236\n",
      "Ecology 6260215 the wbca restrict import endang bird speci\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: the wbca restrict import endang bird speci\n",
      "Similarity: 3.7159865579147166e-235\n",
      "Ecology 6260215 the unit state world biggest buyer exot bird\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: the unit state world biggest buyer exot bird\n",
      "Similarity: 1.1472761276117146e-234\n",
      "Ecology 6260215 the high cost limit offspr toucan make difficult obtain\n",
      "Segment Idea: the export toucan central america lead deforest decreas popul in larg demand toucan us mani keep small cage feed dog food mice the cost fresh fruit special pellet low iron toy high item last month as result toucan requir much larger space fewer find zoo price ring the suppli demand lead concern organ defend wildlif world birdwatch club associ wbca report around million bird affect\n",
      "Student Note: the high cost limit offspr toucan make difficult obtain\n",
      "Similarity: 2.9524728844913183e-234\n",
      "Ecology 6260215 toucan requir low iron diet avoid hemochromatosi\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: toucan requir low iron diet avoid hemochromatosi\n",
      "Similarity: 1.3670350583262574e-235\n",
      "Ecology 6260215 hemochromatosi lead caus death toucan captiv\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: hemochromatosi lead caus death toucan captiv\n",
      "Similarity: 1.5054543777874225e-159\n",
      "Ecology 6260215 hemochromatosi affect parrot finch canari\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: hemochromatosi affect parrot finch canari\n",
      "Similarity: 0\n",
      "Ecology 6260215 hemochromatosi caus excess fluid build make hard toucan breath\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: hemochromatosi caus excess fluid build make hard toucan breath\n",
      "Similarity: 6.98264912296603e-158\n",
      "Ecology 6260215 common symptom hemochromatosi includ openmouth breath swell abdomen\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: common symptom hemochromatosi includ openmouth breath swell abdomen\n",
      "Similarity: 2.175338532125961e-158\n",
      "Ecology 6260215 a vet take liver biopsi check hemochromatosi bird healthi enough\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: a vet take liver biopsi check hemochromatosi bird healthi enough\n",
      "Similarity: 1.2934990504079335e-157\n",
      "Ecology 6260215 golden brown deposit iron liver cell confirm diagnosi hemochromatosi\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: golden brown deposit iron liver cell confirm diagnosi hemochromatosi\n",
      "Similarity: 6.603781816658438e-158\n",
      "Ecology 6260215 an enlarg liver confirm whether hemochromatosi present\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: an enlarg liver confirm whether hemochromatosi present\n",
      "Similarity: 1.2352556177084735e-235\n",
      "Ecology 6260215 enlarg heart occur hemochromatosi doctor know\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: enlarg heart occur hemochromatosi doctor know\n",
      "Similarity: 2.3120046804627377e-236\n",
      "Ecology 6260215 hemochromatosi enlarg toucan liver life threaten\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: hemochromatosi enlarg toucan liver life threaten\n",
      "Similarity: 2.3120046804627377e-236\n",
      "Ecology 6260215 a phlebotomi one way treat hemochromatosi bird decreas iron content\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: a phlebotomi one way treat hemochromatosi bird decreas iron content\n",
      "Similarity: 2.7362945751677836e-234\n",
      "Ecology 6260215 a phlebotomi practic draw blood\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: a phlebotomi practic draw blood\n",
      "Similarity: 1.511414753153129e-160\n",
      "Ecology 6260215 cheap dog food feed toucan low iron content\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: cheap dog food feed toucan low iron content\n",
      "Similarity: 2.586928059943732e-158\n",
      "Ecology 6260215 toucan requir low iron vegetarian diet decreas chanc get hemochromatosi\n",
      "Segment Idea: iron overload caus death captiv lead liver enlarg iron accumul air sac make hard anim breath often result openmouth breath potenti drown fluid leak lung a liver biopsi may reveal golden brown discolor xray may show enlarg due strain heart treatment involv phlebotomi draw blood typic perform time month addit diet low bioavail vegetarian diet rich fruit help mitig iron overload dog food often soybas consid suitabl option although cheaper altern avail\n",
      "Student Note: toucan requir low iron vegetarian diet decreas chanc get hemochromatosi\n",
      "Similarity: 1.3899551864106122e-157\n",
      "Physics 6260218 einstein discov quantum theori\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: einstein discov quantum theori\n",
      "Similarity: 0\n",
      "Physics 6260218 einstein discov stimul emiss\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: einstein discov stimul emiss\n",
      "Similarity: 0\n",
      "Physics 6260218 quantum theori stimul emiss foundat laser scienc\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: quantum theori stimul emiss foundat laser scienc\n",
      "Similarity: 1.3822400629062799e-235\n",
      "Physics 6260218 laser develop maser\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: laser develop maser\n",
      "Similarity: 2.507097868275915e-164\n",
      "Physics 6260218 maser produc microwav radio wave\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: maser produc microwav radio wave\n",
      "Similarity: 3.6242476953415147e-237\n",
      "Physics 6260218 maser invent charl town arthur schawlow receiv nobel prize\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: maser invent charl town arthur schawlow receiv nobel prize\n",
      "Similarity: 4.936844885842939e-81\n",
      "Physics 6260218 gordon gould s main achiev invent laser\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: gordon gould s main achiev invent laser\n",
      "Similarity: 9.516776490428236e-159\n",
      "Physics 6260218 after two decad legal battl gordon gould secur patent laser invent\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: after two decad legal battl gordon gould secur patent laser invent\n",
      "Similarity: 3.050994091421087e-157\n",
      "Physics 6260218 laser come combin word light maser\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: laser come combin word light maser\n",
      "Similarity: 3.5708890042526755e-236\n",
      "Physics 6260218 earli inventor uncertain use laser\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: earli inventor uncertain use laser\n",
      "Similarity: 3.274877479088865e-237\n",
      "Physics 6260218 laser use everywher dvd bluray player surgeri eg lasik barcod scanner email etc\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: laser use everywher dvd bluray player surgeri eg lasik barcod scanner email etc\n",
      "Similarity: 1.196212175949046e-233\n",
      "Physics 6260218 if flashlight like rippl bathtub laser like huge wave sea\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: if flashlight like rippl bathtub laser like huge wave sea\n",
      "Similarity: 1.5987593562768613e-80\n",
      "Physics 6260218 white light mixtur light differ color\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: white light mixtur light differ color\n",
      "Similarity: 1.955229504211885e-159\n",
      "Physics 6260218 a laser make monochromat light\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: a laser make monochromat light\n",
      "Similarity: 2.0982960627856544e-160\n",
      "Physics 6260218 a monochromat light specif color eg red green ultraviolet\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: a monochromat light specif color eg red green ultraviolet\n",
      "Similarity: 7.674815020063662e-158\n",
      "Physics 6260218 a light coher peak trough light wave line precis\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: a light coher peak trough light wave line precis\n",
      "Similarity: 8.247125452867766e-158\n",
      "Physics 6260218 laser beam like align soldier flashlight like crowd commut\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: laser beam like align soldier flashlight like crowd commut\n",
      "Similarity: 1.5764366440411047e-234\n",
      "Physics 6260218 the light specif distanc consist make laser precis power beam energi\n",
      "Segment Idea: the histori laser begin earli th centuri two signific discoveri the concept laser relat visibl light initi develop maser devic research charl town arthur schalow produc monochromat light unlik ordinari light wave mix gordon gould credit develop laser power light beam serv solut particular problem unlik flashlight emit white light akin rippl bathtub laser coher wave similar huge wave sea the key characterist laser includ specif abil travel distanc consist\n",
      "Student Note: the light specif distanc consist make laser precis power beam energi\n",
      "Similarity: 3.628263881349375e-157\n",
      "Physics 6260218 creat laser requir atom electron\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: creat laser requir atom electron\n",
      "Similarity: 1.6117271411381098e-233\n",
      "Physics 6260218 a load atom could solid liquid ga call medium\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: a load atom could solid liquid ga call medium\n",
      "Similarity: 1.2738074657895048e-232\n",
      "Physics 6260218 to creat laser also need someth stimul medium\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: to creat laser also need someth stimul medium\n",
      "Similarity: 3.938107621795947e-79\n",
      "Physics 6260218 a flash tube emit light stimul medium\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: a flash tube emit light stimul medium\n",
      "Similarity: 6.631440338907588e-233\n",
      "Physics 6260218 rubi crystal serv red laser s medium\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: rubi crystal serv red laser s medium\n",
      "Similarity: 5.576354408956027e-233\n",
      "Physics 6260218 rubi crystal absorb energi flash tube absorpt\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: rubi crystal absorb energi flash tube absorpt\n",
      "Similarity: 5.576354408956027e-233\n",
      "Physics 6260218 the electron quickli return origin energi level call grind state\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: the electron quickli return origin energi level call grind state\n",
      "Similarity: 2.2287357007065595e-232\n",
      "Physics 6260218 electron releas energi revert grind state call spontan emiss\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: electron releas energi revert grind state call spontan emiss\n",
      "Similarity: 8.161603624195949e-156\n",
      "Physics 6260218 travel photon stimul alreadyexcit atom make emit photon\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: travel photon stimul alreadyexcit atom make emit photon\n",
      "Similarity: 1.1702534650797613e-232\n",
      "Physics 6260218 stimul emiss doubl light\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: stimul emiss doubl light\n",
      "Similarity: 2.614510115538735e-157\n",
      "Physics 6260218 radio wave xray infrar light laser make electromagnet radiat\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: radio wave xray infrar light laser make electromagnet radiat\n",
      "Similarity: 9.273372099242484e-156\n",
      "Physics 6260218 radiat electron give absorb energi\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: radiat electron give absorb energi\n",
      "Similarity: 1.456359874004723e-233\n",
      "Physics 6260218 shift electron energi level absorpt\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: shift electron energi level absorpt\n",
      "Similarity: 9.331262647643618e-157\n",
      "Physics 6260218 spontan emiss radiat atom give light emit radiat\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: spontan emiss radiat atom give light emit radiat\n",
      "Similarity: 6.693164597921839e-156\n",
      "Physics 6260218 typic medium electron grind state excit state\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: typic medium electron grind state excit state\n",
      "Similarity: 5.576354408956027e-233\n",
      "Physics 6260218 the metast state shortterm excit condit\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: the metast state shortterm excit condit\n",
      "Similarity: 2.975482570578e-233\n",
      "Physics 6260218 we amplifi light use stimul emiss radiat\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: we amplifi light use stimul emiss radiat\n",
      "Similarity: 4.125641103118637e-156\n",
      "Physics 6260218 laser stand light amplif stimul emiss radiat\n",
      "Segment Idea: electron make laser need someth stimul atom initi electron level absorpt electron level follow spontan emiss stimul emiss the process involv electromagnet radiat light result amplif stimul emiss\n",
      "Student Note: laser stand light amplif stimul emiss radiat\n",
      "Similarity: 2.9729879570413887e-79\n",
      "Physics 6260218 quantum smallest quantiti energi\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: quantum smallest quantiti energi\n",
      "Similarity: 6.334273958672937e-85\n",
      "Physics 6260218 to make electron move higher level precis amount energi feed\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: to make electron move higher level precis amount energi feed\n",
      "Similarity: 3.342117741248642e-234\n",
      "Physics 6260218 when laser emit energi creat lot photon ident energi frequenc wavelength\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: when laser emit energi creat lot photon ident energi frequenc wavelength\n",
      "Similarity: 3.226033477195644e-157\n",
      "Physics 6260218 frequenc wavelength determin color light\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: frequenc wavelength determin color light\n",
      "Similarity: 2.753832732561143e-237\n",
      "Physics 6260218 laser light monochromat\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: laser light monochromat\n",
      "Similarity: 2.7668434090040618e-241\n",
      "Physics 6260218 there five laser type solid ga liquid semiconductor fiber\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: there five laser type solid ga liquid semiconductor fiber\n",
      "Similarity: 1.8747096734447747e-234\n",
      "Physics 6260218 dope process replac solid atom impur one\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: dope process replac solid atom impur one\n",
      "Similarity: 1.6437697174500278e-235\n",
      "Physics 6260218 ga laser produc continu beam\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: ga laser produc continu beam\n",
      "Similarity: 1.952058574872517e-83\n",
      "Physics 6260218 ga laser use nobl ga co medium\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: ga laser use nobl ga co medium\n",
      "Similarity: 1.0226441864499518e-158\n",
      "Physics 6260218 co laser use industri cut engrav\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: co laser use industri cut engrav\n",
      "Similarity: 3.226662458910993e-236\n",
      "Physics 6260218 liquid dye laser make laser mani differ color\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: liquid dye laser make laser mani differ color\n",
      "Similarity: 4.543337329682449e-158\n",
      "Physics 6260218 solid liquid ga laser requir expens equip\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: solid liquid ga laser requir expens equip\n",
      "Similarity: 7.369300369719214e-82\n",
      "Physics 6260218 semiconductor small cheap\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: semiconductor small cheap\n",
      "Similarity: 0\n",
      "Physics 6260218 semiconductor laser find cd player printer barcod scanner\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: semiconductor laser find cd player printer barcod scanner\n",
      "Similarity: 4.666095165829976e-235\n",
      "Physics 6260218 a fiber optic thin human hair\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: a fiber optic thin human hair\n",
      "Similarity: 2.7132888949318734e-236\n",
      "Physics 6260218 laser send signal without data loss\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: laser send signal without data loss\n",
      "Similarity: 2.7132888949318734e-236\n",
      "Physics 6260218 data send fiber optic cabl vulner electr interfer\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: data send fiber optic cabl vulner electr interfer\n",
      "Similarity: 4.666095165829976e-235\n",
      "Physics 6260218 use fiber optic cabl result fewer signal dropout\n",
      "Segment Idea: the smallest quantiti energi know quantum laser oper inject precis quantum energi creat photon form electromagnet radiat laser categor variou type includ solid liquid ga fiber laser the creation laser often involv dope use highpow beam ga laser notabl abil produc continu beam achiev high power effici addit laser make use organ dye allow product laser differ color also creat use fiber liquid the concept laser develop individu charl town\n",
      "Student Note: use fiber optic cabl result fewer signal dropout\n",
      "Similarity: 2.7931899651499367e-158\n",
      "Physics 6260218 the jame bond movi goldfing introduc peopl laser\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: the jame bond movi goldfing introduc peopl laser\n",
      "Similarity: 1.2775625193221682e-156\n",
      "Physics 6260218 co laser use cut fabric\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: co laser use cut fabric\n",
      "Similarity: 4.645762113967278e-158\n",
      "Physics 6260218 laser remov skin discolor tumor\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: laser remov skin discolor tumor\n",
      "Similarity: 8.024316936618496e-235\n",
      "Physics 6260218 lasik use laser reshap cornea irrevers procedur\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: lasik use laser reshap cornea irrevers procedur\n",
      "Similarity: 4.504283616057082e-157\n",
      "Physics 6260218 revers lasik place special contact len cornea\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: revers lasik place special contact len cornea\n",
      "Similarity: 6.542132491047196e-234\n",
      "Physics 6260218 barcod scanner util laser data read\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: barcod scanner util laser data read\n",
      "Similarity: 2.904548982262551e-234\n",
      "Physics 6260218 dvd player util laser data read\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: dvd player util laser data read\n",
      "Similarity: 2.904548982262551e-234\n",
      "Physics 6260218 laser also use send receiv signal internet\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: laser also use send receiv signal internet\n",
      "Similarity: 8.609930560759975e-234\n",
      "Physics 6260218 one biggest user laser militari\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: one biggest user laser militari\n",
      "Similarity: 6.097162361421464e-235\n",
      "Physics 6260218 militari use guid weapon missil\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: militari use guid weapon missil\n",
      "Similarity: 7.250788861528686e-235\n",
      "Physics 6260218 strateg defens initi sdi commonli know star war program\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: strateg defens initi sdi commonli know star war program\n",
      "Similarity: 0.006827148052134502\n",
      "Physics 6260218 sdi plan use nuclear reactor power laser space\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: sdi plan use nuclear reactor power laser space\n",
      "Similarity: 1.7946418133746944e-233\n",
      "Physics 6260218 sdi never implement\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: sdi never implement\n",
      "Similarity: 2.2419964357618656e-237\n",
      "Physics 6260218 in us navi test laser weapon system persian gulf\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: in us navi test laser weapon system persian gulf\n",
      "Similarity: 2.8611271095426387e-233\n",
      "Physics 6260218 in low energi state laser use crippl sensor target\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: in low energi state laser use crippl sensor target\n",
      "Similarity: 1.3929276128940716e-156\n",
      "Physics 6260218 in high energi state laser destroy target altogeth\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: in high energi state laser destroy target altogeth\n",
      "Similarity: 1.3636328927646374e-233\n",
      "Physics 6260218 laser cheaper convent missil cost energi take make laser\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: laser cheaper convent missil cost energi take make laser\n",
      "Similarity: 2.8611271095426387e-233\n",
      "Physics 6260218 laser cheaper requir hardwar missil storag\n",
      "Segment Idea: the movi goldfing featur jame bond laser numer realworld applic the laser use carbon dioxid laser industri cut also util lasik surgeri remov tumor consid strateg defens initi sdi potenti weapon addit orbit satellit employ xray laser demonstr pervas use laser variou field\n",
      "Student Note: laser cheaper requir hardwar missil storag\n",
      "Similarity: 2.4424248271132994e-234\n",
      "Statistics 6260216 statist involv collect analyz data\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: statist involv collect analyz data\n",
      "Similarity: 2.7607725720371986e-06\n",
      "Statistics 6260216 the popul entir collect object individu inform desir\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: the popul entir collect object individu inform desir\n",
      "Similarity: 3.979901150188741e-158\n",
      "Statistics 6260216 a popul broad like peopl countri\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: a popul broad like peopl countri\n",
      "Similarity: 3.8118512946371686e-236\n",
      "Statistics 6260216 a popul specif like colleg student\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: a popul specif like colleg student\n",
      "Similarity: 2.48207465472675e-159\n",
      "Statistics 6260216 factor like birth death immigr emigr continu chang popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: factor like birth death immigr emigr continu chang popul\n",
      "Similarity: 1.338601015627708e-234\n",
      "Statistics 6260216 research use sampl rather popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: research use sampl rather popul\n",
      "Similarity: 4.4266661313457617e-237\n",
      "Statistics 6260216 it often possibl collect true popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: it often possibl collect true popul\n",
      "Similarity: 4.218506908361334e-236\n",
      "Statistics 6260216 a sampl subset popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: a sampl subset popul\n",
      "Similarity: 8.133368759199328e-85\n",
      "Statistics 6260216 capit uppercas n refer popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: capit uppercas n refer popul\n",
      "Similarity: 3.999944385595761e-237\n",
      "Statistics 6260216 lowercas n refer sampl\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: lowercas n refer sampl\n",
      "Similarity: 1.3426582777875818e-238\n",
      "Statistics 6260216 finit popul statist collect sampl use random small group peopl\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: finit popul statist collect sampl use random small group peopl\n",
      "Similarity: 4.392468876559518e-234\n",
      "Statistics 6260216 a good sampl look like popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: a good sampl look like popul\n",
      "Similarity: 1.708918034970378e-82\n",
      "Statistics 6260216 there two type statist descript statist inferenti statist\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: there two type statist descript statist inferenti statist\n",
      "Similarity: 0.00022800782499828143\n",
      "Statistics 6260216 descript statist describ data like summari data\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: descript statist describ data like summari data\n",
      "Similarity: 8.12218759281572e-82\n",
      "Statistics 6260216 exampl descript statist averag maximum minimum\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: exampl descript statist averag maximum minimum\n",
      "Similarity: 2.087167679551854e-159\n",
      "Statistics 6260216 inferenti statist use infer predict data\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: inferenti statist use infer predict data\n",
      "Similarity: 2.746867143732588e-159\n",
      "Statistics 6260216 the weather station sampl weather entir citi popul\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: the weather station sampl weather entir citi popul\n",
      "Similarity: 4.165504395094664e-158\n",
      "Statistics 6260216 we draw infer weather place without weather station\n",
      "Segment Idea: statist involv collect analyz data popul refer entir group object individu interest commun colleg student howev alway possibl obtain data entir popul sampl subset popul use instead instanc popul might sampl a good sampl resembl popul although achiev challeng there two main type statist descript statist describ characterist data highest lowest valu inferenti statist make predict infer data avail use data weather station make statement place without weather station\n",
      "Student Note: we draw infer weather place without weather station\n",
      "Similarity: 0.0001867466759666178\n",
      "Statistics 6260216 descript statist graph describ character\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: descript statist graph describ character\n",
      "Similarity: 1.3419022662081291e-163\n",
      "Statistics 6260216 descript statist tell sampl\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: descript statist tell sampl\n",
      "Similarity: 6.886409928455468e-166\n",
      "Statistics 6260216 inferenti statist tell popul\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: inferenti statist tell popul\n",
      "Similarity: 4.7413199681667856e-89\n",
      "Statistics 6260216 random sampl best way collect data\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: random sampl best way collect data\n",
      "Similarity: 3.006473766930059e-85\n",
      "Statistics 6260216 random sampl mean everyon popul equal like pick\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: random sampl mean everyon popul equal like pick\n",
      "Similarity: 2.1897190215235922e-83\n",
      "Statistics 6260216 data collect do two way via experi direct observ\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: data collect do two way via experi direct observ\n",
      "Similarity: 9.216032476312705e-83\n",
      "Statistics 6260216 cours experi call research method\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: cours experi call research method\n",
      "Similarity: 1.050095272403869e-163\n",
      "Statistics 6260216 a survey common type direct observ\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: a survey common type direct observ\n",
      "Similarity: 4.4377027278520517e-162\n",
      "Statistics 6260216 there three type observ studi crosssect retrospect prospect studi\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: there three type observ studi crosssect retrospect prospect studi\n",
      "Similarity: 1.341862105959371e-05\n",
      "Statistics 6260216 the common type observ studi crosssect studi\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: the common type observ studi crosssect studi\n",
      "Similarity: 2.800393351472315e-07\n",
      "Statistics 6260216 crosssect studi take measur give time look data\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: crosssect studi take measur give time look data\n",
      "Similarity: 3.7821565116348736e-160\n",
      "Statistics 6260216 crosssect studi stop time\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: crosssect studi stop time\n",
      "Similarity: 6.886409928455468e-166\n",
      "Statistics 6260216 retrospect studi look exist data alreadi collect\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: retrospect studi look exist data alreadi collect\n",
      "Similarity: 3.420228690679227e-84\n",
      "Statistics 6260216 retrospect studi go back time\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: retrospect studi go back time\n",
      "Similarity: 1.1311850917716326e-09\n",
      "Statistics 6260216 robert fogel conduct retrospect studi civil war medic record\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: robert fogel conduct retrospect studi civil war medic record\n",
      "Similarity: 1.0170850941606571e-159\n",
      "Statistics 6260216 a lot retrospect studi do peopl collect data\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: a lot retrospect studi do peopl collect data\n",
      "Similarity: 3.61363417803029e-160\n",
      "Statistics 6260216 prospect studi go forward time\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: prospect studi go forward time\n",
      "Similarity: 1.0497586622291569e-86\n",
      "Statistics 6260216 economist call prospect studi longitudin studi\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: economist call prospect studi longitudin studi\n",
      "Similarity: 3.472690055155198e-162\n",
      "Statistics 6260216 the person collect data prospect studi usual person design studi\n",
      "Segment Idea: statist categor two type descript inferenti descript statist involv graph describ data provid inform sampl in contrast inferenti statist tell someth popul sampl compar averag weight peopl major campu to collect data random sampl use everi individu equal like pick there two primari way collect data experi direct observ experi requir knowledg design typic cover research method direct observ encompass three type observ studi crosssect retrospect prospect crosssect studi common type involv collect data give time examin measur height men women time data collect retrospect studi go back time often use data alreadi collect typic research prospect studi hand involv go forward time certain point time studi stop\n",
      "Student Note: the person collect data prospect studi usual person design studi\n",
      "Similarity: 4.998284556099838e-159\n",
      "Statistics 6260216 in observ studi report s happen without influenc activ\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: in observ studi report s happen without influenc activ\n",
      "Similarity: 5.349961212319254e-82\n",
      "Statistics 6260216 the conclus might wrong confound variabl\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: the conclus might wrong confound variabl\n",
      "Similarity: 6.302700268609813e-161\n",
      "Statistics 6260216 the research often forget collect data regard confound variabl\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: the research often forget collect data regard confound variabl\n",
      "Similarity: 1.062823751389874e-158\n",
      "Statistics 6260216 observ studi show causat\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: observ studi show causat\n",
      "Similarity: 6.198948667189928e-164\n",
      "Statistics 6260216 it imposs collect possibl variabl observ studi\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: it imposs collect possibl variabl observ studi\n",
      "Similarity: 6.210272832188112e-160\n",
      "Statistics 6260216 confound lurk variabl hide variabl affect result\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: confound lurk variabl hide variabl affect result\n",
      "Similarity: 4.683900884592764e-83\n",
      "Statistics 6260216 we conclud smoke caus lung cancer base observ studi\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: we conclud smoke caus lung cancer base observ studi\n",
      "Similarity: 9.449987967984928e-159\n",
      "Statistics 6260216 confound variabl bad health habit caus smoke behavior lung cancer\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: confound variabl bad health habit caus smoke behavior lung cancer\n",
      "Similarity: 1.7506524622765931e-81\n",
      "Statistics 6260216 the firefight scene fire damag observ\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: the firefight scene fire damag observ\n",
      "Similarity: 1.368871754058964e-237\n",
      "Statistics 6260216 size fire confound variabl\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: size fire confound variabl\n",
      "Similarity: 6.198948667189928e-164\n",
      "Statistics 6260216 the foot size kid correl intellig\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: the foot size kid correl intellig\n",
      "Similarity: 9.67938499869734e-238\n",
      "Statistics 6260216 age kid confound variabl\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: age kid confound variabl\n",
      "Similarity: 4.383318638797429e-164\n",
      "Statistics 6260216 in experiment studi research manipul variabl\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: in experiment studi research manipul variabl\n",
      "Similarity: 7.495216003160248e-161\n",
      "Statistics 6260216 to know whether femal cricket choos mate base health manipul health male cricket\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: to know whether femal cricket choos mate base health manipul health male cricket\n",
      "Similarity: 3.054360965374669e-234\n",
      "Statistics 6260216 an experiment studi draw causat\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: an experiment studi draw causat\n",
      "Similarity: 3.843163296763475e-162\n",
      "Statistics 6260216 random ensur confound variabl equal across group\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: random ensur confound variabl equal across group\n",
      "Similarity: 5.465734008297762e-160\n",
      "Statistics 6260216 random much like duct tape statist\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: random much like duct tape statist\n",
      "Similarity: 1.1510793509301975e-237\n",
      "Statistics 6260216 ronald fish consid father modern day statist experiment design\n",
      "Segment Idea: in observ studi one observ without affect action key collect data one observ possibl show causat due confound variabl hide variabl may collect affect result for instanc observ smoke associ higher likelihood get cancer unclear whether smoke like caus cancer relat bad health habit similarli firefight associ damag may due size fire requir firefight therefor one alway worri confound variabl in contrast experiment studi one affect action studi deal confound control variabl random see exampl studi effect three differ size bug randomli assign affect thi approach notabl advoc ronald fisher\n",
      "Student Note: ronald fish consid father modern day statist experiment design\n",
      "Similarity: 1.5436714001395256e-235\n",
      "Statistics 6260216 experi expens difficult run uneth\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: experi expens difficult run uneth\n",
      "Similarity: 1.098599005193904e-240\n",
      "Statistics 6260216 if causal focu need run experi\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: if causal focu need run experi\n",
      "Similarity: 3.4530231604902396e-239\n",
      "Statistics 6260216 we conduct experi smoke lung cancer ethic issu\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: we conduct experi smoke lung cancer ethic issu\n",
      "Similarity: 4.137723788675289e-237\n",
      "Statistics 6260216 vaccin trial differ smoke studi intent caus harm\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: vaccin trial differ smoke studi intent caus harm\n",
      "Similarity: 3.738855505831007e-237\n",
      "Statistics 6260216 observ studi fraught issu\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: observ studi fraught issu\n",
      "Similarity: 0\n",
      "Statistics 6260216 simpl random sampl sr mean everi member sampl equal like pick\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: simpl random sampl sr mean everi member sampl equal like pick\n",
      "Similarity: 3.443330241330356e-05\n",
      "Statistics 6260216 in conveni sampl sampl base eas access\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: in conveni sampl sampl base eas access\n",
      "Similarity: 2.6900869619207267e-84\n",
      "Statistics 6260216 in stratifi sampl particip select subgroup popul\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: in stratifi sampl particip select subgroup popul\n",
      "Similarity: 3.7330569452114565e-161\n",
      "Statistics 6260216 a sampl unbias\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: a sampl unbias\n",
      "Similarity: 5.329040091938566e-247\n",
      "Statistics 6260216 a bias sampl overli repres one group\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: a bias sampl overli repres one group\n",
      "Similarity: 6.817783778931808e-238\n",
      "Statistics 6260216 the result survey shop mall middl weekday gener work weekday\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: the result survey shop mall middl weekday gener work weekday\n",
      "Similarity: 5.531220903013963e-236\n",
      "Statistics 6260216 when conduct survey think gener result\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: when conduct survey think gener result\n",
      "Similarity: 4.106359710724353e-239\n",
      "Statistics 6260216 overrepresent underrepresent produc select bia\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: overrepresent underrepresent produc select bia\n",
      "Similarity: 6.360453702272099e-164\n",
      "Statistics 6260216 nonrespons bia occur particip ignor refus answer survey\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: nonrespons bia occur particip ignor refus answer survey\n",
      "Similarity: 1.3924164358665624e-83\n",
      "Statistics 6260216 respons bia aris research ask mislead question\n",
      "Segment Idea: to answer research question experi consid gold standard conduct one easi due constraint cost ethic consider requir lot work ensur question welldefin feasibl certain experi uneth unless involv anim subject case deliber harm sometim inflict in research variou sampl method employ includ simpl random sampl sr everi individu equal chanc select conveni sampl involv select sampl base eas stratifi sampl popul split differ group men versu women high school versu colleg student to ensur valid result sampl must unbias mean favor particular subgroup crucial identifi target popul avoid select bia select individu repres entir popul addit research must awar nonrespons bia occur respons respons bia aris question word bias way\n",
      "Student Note: respons bia aris research ask mislead question\n",
      "Similarity: 2.322459735192974e-84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\rohai\\AppData\\Local\\Temp\\ipykernel_9668\\2867503854.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  similarity_df = similarity_df._append({'Similarity': similarity, 'Label': row['label']}, ignore_index=True)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(columns=['Similarity', 'Label'])\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    print(row['Topic'], row['ID'], row['IdeaUnit']) \n",
    "    \n",
    "    matching_row = notes_df[(notes_df['Topic'] == row['Topic']) & (notes_df['ID'] == row['ID'])]\n",
    "    if not matching_row.empty:\n",
    "       \n",
    "        # print(\"Matching row found in notes_df:\")\n",
    "        # print(matching_row[['Segment1_Notes', 'Segment2_Notes', 'Segment3_Notes', 'Segment4_Notes']])\n",
    "        \n",
    "        # Print the first 5 rows of the matching row\n",
    "        # for col in ['Segment1_Notes', 'Segment2_Notes', 'Segment3_Notes', 'Segment4_Notes']:\n",
    "        #     print(f\"{col}: {matching_row[col].values[0]}\")\n",
    "            \n",
    "        segment_idea = matching_row[f'Segment{row[\"Segment\"]}_Notes'].values[0]\n",
    "        student_note = row['IdeaUnit']\n",
    "        print(\"Segment Idea:\", segment_idea)\n",
    "        print(\"Student Note:\", student_note)\n",
    "        \n",
    "                \n",
    "        # Find the similarity between the two segments through Jaccard Similarity\n",
    "        segment_words = set(segment_idea.split())\n",
    "        student_words = set(student_note.split())\n",
    "        common_words = segment_words.intersection(student_words)\n",
    "        similarity = len(common_words) / (len(segment_words) + len(student_words) - len(common_words)) if (len(segment_words) + len(student_words) - len(common_words)) > 0 else 0\n",
    "        \n",
    "        print(\"Similarity:\", similarity)\n",
    "        \n",
    "        # Store the similarity and label in the similarity_df\n",
    "        similarity_df = similarity_df._append({'Similarity': similarity, 'Label': row['label']}, ignore_index=True)\n",
    "       \n",
    "    else:\n",
    "        print(\"No matching row found for index:\", index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55a8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.023060e-160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.542691e-158</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.139193e-235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.755848e-236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.019036e-81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Similarity  Label\n",
       "0  5.023060e-160    1.0\n",
       "1  2.542691e-158    1.0\n",
       "2  5.139193e-235    1.0\n",
       "3  6.755848e-236    0.0\n",
       "4   8.019036e-81    1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0059c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rohai\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.01\n",
      "Best Accuracy: 0.5137\n",
      "Best F1 Score: 0.3487\n",
      "Best Precision: 0.2639\n",
      "Best Recall: 0.5137\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the best threshold for the similarity score from the similarity_df by iterating through different thresholds\n",
    "thresholds = [i * 0.01 for i in range(101)]\n",
    "best_threshold = None\n",
    "best_accuracy = 0.0\n",
    "best_f1_score = 0.0\n",
    "best_precision = 0.0\n",
    "best_recall = 0.0\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "# Iterate through different thresholds to find the best one\n",
    "for threshold in thresholds:\n",
    "    # Create a binary prediction based on the threshold\n",
    "    similarity_df['Predicted'] = (similarity_df['Similarity'] >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy, f1, precision, recall = evaluate_model(similarity_df['Label'], similarity_df['Predicted'])\n",
    "    \n",
    "    # Check if this is the best threshold so far\n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_threshold = threshold\n",
    "        best_accuracy = accuracy\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "        \n",
    "# Print the best threshold and its corresponding metrics\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")\n",
    "print(f\"Best Precision: {best_precision:.4f}\")\n",
    "print(f\"Best Recall: {best_recall:.4f}\")\n",
    "\n",
    "# Plot the confusion matrix for the best threshold\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Create a binary prediction based on the best threshold\n",
    "similarity_df['Predicted'] = (similarity_df['Similarity'] >= best_threshold).astype(int)\n",
    "\n",
    "# Plot the confusion matrix for the best threshold\n",
    "plot_confusion_matrix(similarity_df['Label'], similarity_df['Predicted'], title='Confusion Matrix for Best Threshold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55e776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment</th>\n",
       "      <th>IdeaUnit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260230</td>\n",
       "      <td>1</td>\n",
       "      <td>declar knowledg factual statement</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260230</td>\n",
       "      <td>1</td>\n",
       "      <td>imper knowledg solv problem accomplish task</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260230</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm instruct step complet specif order</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260230</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm outlin begin middl end</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ComputerScience</td>\n",
       "      <td>6260230</td>\n",
       "      <td>1</td>\n",
       "      <td>algorithm contain loop instruct tell program r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment            Topic       ID  Segment  \\\n",
       "0           2  ComputerScience  6260230        1   \n",
       "1           2  ComputerScience  6260230        1   \n",
       "2           2  ComputerScience  6260230        1   \n",
       "3           2  ComputerScience  6260230        1   \n",
       "4           2  ComputerScience  6260230        1   \n",
       "\n",
       "                                            IdeaUnit  label  \n",
       "0                  declar knowledg factual statement    1.0  \n",
       "1        imper knowledg solv problem accomplish task    1.0  \n",
       "2       algorithm instruct step complet specif order    0.0  \n",
       "3                   algorithm outlin begin middl end    0.0  \n",
       "4  algorithm contain loop instruct tell program r...    1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('note classification\\\\test.csv', encoding='cp1252')\n",
    "\n",
    "test_df = test_df.dropna(subset=['label'])\n",
    "\n",
    "test_df['IdeaUnit'] = test_df['IdeaUnit'].apply(perform_preprocessing)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc2d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohai\\AppData\\Local\\Temp\\ipykernel_9668\\573507131.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_preds = test_preds._append({'Similarity': similarity, 'Label': row['label']}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "test_preds = pd.DataFrame(columns=['Similarity', 'Label'])\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    # print(row['Topic'], row['ID'], row['IdeaUnit']) \n",
    "    \n",
    "    matching_row = notes_df[(notes_df['Topic'] == row['Topic']) & (notes_df['ID'] == row['ID'])]\n",
    "    if not matching_row.empty:\n",
    "            \n",
    "        segment_idea = matching_row[f'Segment{row[\"Segment\"]}_Notes'].values[0]\n",
    "        student_note = row['IdeaUnit']\n",
    "        # print(\"Segment Idea:\", segment_idea)\n",
    "        # print(\"Student Note:\", student_note)\n",
    "        \n",
    "        # Find the similarity between the two segments\n",
    "        segment_words = set(segment_idea.split())\n",
    "        student_words = set(student_note.split())\n",
    "        \n",
    "        common_words = segment_words.intersection(student_words)\n",
    "        \n",
    "        similarity = len(common_words) / (len(segment_words) + len(student_words) - len(common_words)) if (len(segment_words) + len(student_words) - len(common_words)) > 0 else 0\n",
    "        # print(\"Similarity:\", similarity)\n",
    "        \n",
    "        test_preds = test_preds._append({'Similarity': similarity, 'Label': row['label']}, ignore_index=True)\n",
    "       \n",
    "    else:\n",
    "        print(\"No matching row found for index:\", index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f1c8049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6444\n",
      "Test F1 Score: 0.5523\n",
      "Test Precision: 0.6129\n",
      "Test Recall: 0.6444\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = (test_preds['Similarity'] >= best_threshold).astype(int)\n",
    "\n",
    "accuracy, f1, precision, recall = evaluate_model(test_preds['Label'], preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(test_preds['Label'], preds, title='Confusion Matrix for Test Set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
