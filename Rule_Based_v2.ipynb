{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas nltk python-Levenshtein\n",
        "!python -m nltk.downloader wordnet punkt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgX5mgDoqq2H",
        "outputId": "faf3e71b-66cb-45f3-a0e3-8a561ba8e655"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n",
            "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "dZFOYjH0rpyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OH1avN8Mpk9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import Levenshtein\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data and Format"
      ],
      "metadata": {
        "id": "IoSt1XAlrwR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(notes_path, labels_path):\n",
        "    encodings = ['utf-8', 'cp1252', 'latin1', 'iso-8859-1']\n",
        "\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            notes_df = pd.read_csv(notes_path, encoding=encoding)\n",
        "            labels_df = pd.read_csv(labels_path, encoding=encoding)\n",
        "            break\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    # Merge notes with labels using ID only\n",
        "    merged = labels_df.merge(\n",
        "        notes_df,\n",
        "        how='left',\n",
        "        on=['ID'],\n",
        "        suffixes=('', '_note')\n",
        "    )\n",
        "\n",
        "    # Extract the correct segment notes\n",
        "    merged['Note'] = merged.apply(\n",
        "        lambda x: x[f'Segment{x.Segment}_Notes'] if pd.notna(x[f'Segment{x.Segment}_Notes']) else \"\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return merged[['ID', 'Segment', 'IdeaUnit', 'Note', 'label']]"
      ],
      "metadata": {
        "id": "TSV9akcUrxCf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess all text:"
      ],
      "metadata": {
        "id": "kRdBmzEVsUe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess(text):\n",
        "    \"\"\"Clean and tokenize text.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "\n",
        "    # Standardize text\n",
        "    text = (text.lower()\n",
        "            .replace(\"ex)\", \"example\")\n",
        "            .replace(\"-\", \" \")\n",
        "            .replace(\":\", \" \"))\n",
        "\n",
        "    # Tokenize and remove punctuation\n",
        "    words = [w for w in word_tokenize(text) if w.isalnum()]\n",
        "\n",
        "    # Lemmatize (reduce to base form)\n",
        "    return [lemmatizer.lemmatize(w) for w in words]"
      ],
      "metadata": {
        "id": "-esFERJXsFET"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rules for determining 1 or 0"
      ],
      "metadata": {
        "id": "PISnzHN2s5jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms(word):\n",
        "    \"\"\"Get synonyms using WordNet.\"\"\"\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name().lower())\n",
        "    return synonyms\n",
        "\n",
        "def keyword_overlap(idea_unit, note, threshold=0.5):\n",
        "    \"\"\"Check if sufficient keywords match between IdeaUnit and Note.\"\"\"\n",
        "    idea_words = preprocess(idea_unit)\n",
        "    note_words = preprocess(note)\n",
        "\n",
        "    if not idea_words:\n",
        "        return False\n",
        "\n",
        "    # Expand with synonyms\n",
        "    synonym_expanded = set(idea_words)\n",
        "    for word in idea_words:\n",
        "        synonym_expanded.update(get_synonyms(word))\n",
        "\n",
        "    # Count overlaps\n",
        "    overlap = len([w for w in note_words if w in synonym_expanded])\n",
        "    return (overlap / len(idea_words)) >= threshold\n",
        "\n",
        "#Verify proper nouns and technical terms are correctly spelled.\n",
        "\n",
        "def strict_typo_check(idea_unit, note, max_distance=2):\n",
        "    idea_proper_nouns = [w for w in preprocess(idea_unit) if w[0].isupper()]\n",
        "\n",
        "    for pn in idea_proper_nouns:\n",
        "        # Find closest match in note\n",
        "        note_words = preprocess(note)\n",
        "        closest_match = min(\n",
        "            [Levenshtein.distance(pn, nw) for nw in note_words],\n",
        "            default=max_distance+1\n",
        "        )\n",
        "\n",
        "        if closest_match > max_distance:\n",
        "            return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "mikvn70xsrfp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(idea_unit, note, threshold=0.5):\n",
        "    \"\"\"Rule-based classifier.\"\"\"\n",
        "    # Negative rules\n",
        "    if len(preprocess(note)) < 5:\n",
        "        return 0\n",
        "\n",
        "    if not strict_typo_check(idea_unit, note):\n",
        "        return 0\n",
        "\n",
        "    # Positive rules\n",
        "    if keyword_overlap(idea_unit, note, threshold):\n",
        "        return 1\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "AAz_UUA4tVsd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(y_true, y_pred):\n",
        "    \"\"\"Print classification metrics.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "SR5iS0pcjh-5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data (example paths)\n",
        "train_data = load_data(\"/content/drive/MyDrive/FinalProj/Notes.csv\", \"/content/drive/MyDrive/FinalProj/train.csv\")\n",
        "test_data = load_data(\"/content/drive/MyDrive/FinalProj/Notes.csv\", \"/content/drive/MyDrive/FinalProj/test.csv\")\n",
        "# Train threshold optimization\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0"
      ],
      "metadata": {
        "id": "cFskSAZatasO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in np.arange(0.3, 0.71, 0.02):\n",
        "    train_data['pred'] = train_data.apply(\n",
        "        lambda x: predict_label(x['IdeaUnit'], x['Note'], threshold),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    f1 = f1_score(train_data['label'], train_data['pred'])\n",
        "    print(f\"Threshold {threshold}: F1 = {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"\\nBest threshold: {best_threshold} (F1={best_f1:.4f})\")\n",
        "\n",
        "# Evaluate on training data\n",
        "print(\"\\nTraining Set Performance:\")\n",
        "print_metrics(train_data['label'], train_data['pred'])\n",
        "\n",
        "# Test evaluation\n",
        "print(\"\\nEvaluating on test data...\")\n",
        "# Drop NaN labels (recommended)\n",
        "test_data_clean = test_data.dropna(subset=['label'])\n",
        "\n",
        "# Generate predictions\n",
        "test_data_clean['pred'] = test_data_clean.apply(\n",
        "    lambda x: predict_label(x['IdeaUnit'], x['Note'], best_threshold),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print_metrics(test_data_clean['label'],test_data_clean['pred'])\n",
        "\n",
        "# Save predictions\n",
        "test_data_clean[['ID', 'Segment', 'IdeaUnit', 'pred']].to_csv(\"predictions.csv\", index=False)\n",
        "print(\"\\nPredictions saved to 'predictions2.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyW0EdsvtxKs",
        "outputId": "40302dcd-1caf-4322-a59e-2987028e992e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold 0.3: F1 = 0.6630\n",
            "Threshold 0.32: F1 = 0.6685\n",
            "Threshold 0.34: F1 = 0.6686\n",
            "Threshold 0.36000000000000004: F1 = 0.6648\n",
            "Threshold 0.38000000000000006: F1 = 0.6648\n",
            "Threshold 0.4000000000000001: F1 = 0.6764\n",
            "Threshold 0.4200000000000001: F1 = 0.6764\n",
            "Threshold 0.4400000000000001: F1 = 0.6667\n",
            "Threshold 0.46000000000000013: F1 = 0.6667\n",
            "Threshold 0.48000000000000015: F1 = 0.6727\n",
            "Threshold 0.5000000000000002: F1 = 0.6667\n",
            "Threshold 0.5200000000000002: F1 = 0.6667\n",
            "Threshold 0.5400000000000003: F1 = 0.6709\n",
            "Threshold 0.5600000000000003: F1 = 0.6645\n",
            "Threshold 0.5800000000000003: F1 = 0.6623\n",
            "Threshold 0.6000000000000003: F1 = 0.6579\n",
            "Threshold 0.6200000000000003: F1 = 0.6645\n",
            "Threshold 0.6400000000000003: F1 = 0.6554\n",
            "Threshold 0.6600000000000004: F1 = 0.6554\n",
            "Threshold 0.6800000000000004: F1 = 0.6621\n",
            "Threshold 0.7000000000000004: F1 = 0.6644\n",
            "\n",
            "Best threshold: 0.4000000000000001 (F1=0.6764)\n",
            "\n",
            "Training Set Performance:\n",
            "Confusion Matrix:\n",
            "[[60 71]\n",
            " [27 97]]\n",
            "\n",
            "Accuracy: 0.6157\n",
            "Precision: 0.5774\n",
            "Recall: 0.7823\n",
            "F1 Score: 0.6644\n",
            "\n",
            "Evaluating on test data...\n",
            "\n",
            "Test Set Performance:\n",
            "Confusion Matrix:\n",
            "[[3063 3287]\n",
            " [ 478 3113]]\n",
            "\n",
            "Accuracy: 0.6213\n",
            "Precision: 0.4864\n",
            "Recall: 0.8669\n",
            "F1 Score: 0.6232\n",
            "\n",
            "Predictions saved to 'predictions2.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-3d619329c3ac>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data_clean['pred'] = test_data_clean.apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Missing labels in test: {test_data['label'].isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPJu7zrUkHkD",
        "outputId": "6037a6d2-485e-48b0-ee6b-64648b20c648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing labels in test: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg3l-PoijKaC",
        "outputId": "b1a2e8ba-6a01-4477-ba77-b532920eb0ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}